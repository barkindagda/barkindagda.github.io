<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Barkin Dagda – Portfolio</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
      color: #333;
      line-height: 1.6;
    }

    header {
      text-align: center;
      padding: 2rem 1rem 1rem;
      background-color: #2c3e50;
      color: white;
    }

    header img {
      width: 150px;
      height: 150px;
      border-radius: 50%;
      object-fit: cover;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
      margin-bottom: 1rem;
    }

    section {
      padding: 1.5rem 10%;
    }

    h2 {
      border-bottom: 2px solid #ccc;
      padding-bottom: 0.5rem;
      margin-bottom: 1rem;
      color: #2c3e50;
    }

    .project {
      margin-bottom: 2rem;
      background: white;
      padding: 1rem;
      border-radius: 10px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }

    .media-placeholder {
      background: #eaeaea;
      border: 2px dashed #ccc;
      padding: 1rem;
      margin-top: 1rem;
      text-align: center;
      color: #777;
      font-style: italic;
    }
  </style>
</head>

<body>
  <header>
    <img src="Barkin_photo.jpeg" alt="Barkin Dagda">
    <h1>Barkin Dagda</h1>
    <p>AI & Robotics Researcher | PhD in Automotive Engineering</p>
  </header>

  <section>
    <h2>Qualifications</h2>
    <p>PhD in Automotive Engineering – University of Surrey</p>
    <p>BEng in Mechanical Engineering – [Your Previous University]</p>
  </section>

  <section>
    <h2>Experience</h2>
    <p>Researcher at Connected & Autonomous Vehicles Lab, University of Surrey</p>
    <p>Research Assistant on digital twins and warehouse robotics</p>
  </section>

  <section>
    <h2>Projects</h2>

    <div class="project">
      <h3>HighwayLLM: Decision-Making and Navigation in Highway Driving with RL-Informed Language Model</h3>
      <p>This study presents a novel approach, HighwayLLM, which harnesses the reasoning capabilities of large language models (LLMs) to predict future waypoints for ego-vehicle navigation, combined with a pre-trained RL model for high-level planning. The method integrates LLM, RL, and PID-based control to create interpretable, safe, and efficient navigation strategies for autonomous driving.</p>
      <div class="media-placeholder">[Insert image or video of HighwayLLM here]</div>
    </div>

    <div class="project">
      <h3>GeoVLM: Improving Autonomous Vehicle Geolocalisation Using Vision-Language Matching</h3>
      <p>GeoVLM leverages the zero-shot capabilities of vision-language models to enable interpretable cross-view geo-localisation. It enhances match accuracy on benchmarks like VIGOR and CVUK using a trainable reranking method. [<a href="https://github.com/barkindagda/GeoVLM" target="_blank">View Code</a>]</p>
      <div class="media-placeholder">[Insert image or video of GeoVLM here]</div>
    </div>

    <div class="project">
      <h3>Cyclopic AMR Digital Twin Model Load Balancing</h3>
      <p>Digital twin model for an autonomous warehouse robot with advanced load balancing and wheel height control, enabling stability in delivery operations. AI algorithms provide dynamic balancing and precise pitch/roll control for improved efficiency.</p>
      <div class="media-placeholder">[Insert image or video of Cyclopic AMR here]</div>
    </div>

  </section>
</body>

</html>
